---
title: "A3"
author: "Group 7"
date: "November 12th, 2024"
output: pdf_document
---

List your group members, including their student numbers, here:

- Micky Fragomeni (169083094)
- Andrew Baldassarra (169109507)
- Luka Zubac (169099010)
- Nav (210559830)
- Tharun (210731980)

You **must** be in a group in MyLS in order to see the DropBox used for submission. Even if you're alone, you must join a group by yourself.

You **must** be in a group with people from the same section as you. MyLS does not allow for groups including students from both Data100A and Data100B.

```{r setup, include=FALSE}
# echo = FALSE will set the Rmd to *not* show the R code. Don't change this.
# You may change the default figure width and figure height as you please.
knitr::opts_chunk$set(echo = FALSE, message = FALSE, fig.width = 6)

# Put any libraries that you need to load here.
# DO NOT PUT "install.packages()" IN AN RMD FILE!!!
library(tidyverse)
library(arrow)
library(tinytex)
```


# Instructions

You are encouraged to remove this instruction section prior to submission.

It is recommended that you follow the structure of this template. The text is all placeholder - you are free to change any/all wording as you please, but it is very helpful for the grading process if you keep the same structure. Anything in <<double angle brackets>> definitely needs to be changed, but you are free to change any/all sentences!

Note that all of the code is *hidden* by default. This file will be graded based on the insights, not the code.

You will only submit the PDF version of this document. To knit to PDF, you'll need to run `install.packages("tinytex")` in the console, followed by `tinytex::install_tinytex()` (DO NOT PUT THESE COMMANDS IN AN RMD FILE!!!). If you encounter errors in "Knit to PDF", you can "knit to html" and then print the html file to PDF using your operating system's PDF view (e.g. Adobe Acrobat). Only standalone PDF files will be accepted by MyLS.

# Abstract
In this report, we are analyzing the relationships between the data results from cyclone intensity, sea ice extent, and climate awareness using the cleaned datasets assigned for completion in part 1. Through the combination of presented/shown insights from these three data sources, we can show and explore some interesting themes, such as whether cyclone severity is actually related to sea ice extent and in what ways.
Further analyzing the 3 datasets and their relations, we can also make connections to determine whether climate awareness correlates with specifec natural disasters like sea ice and cyclones and how etc... Through the use and ability to undersand, summary statistics, visualizations, and correlations, we can investigate and conclude with the help of supporting insights, the issues around climate change perceptions/impacts and the relation shown.

# Introduction
Climate change has been a major global issue with significant impacts on the environment and human life. Understanding the relationships between natural events, such as hurricane intensity and ice extent, and human perspectives on climate change is essential.

In this report, we explore aspects of climate change through three datasets: hurricane intensity, sea ice extent, and climate awareness across various countries. We aim to find potential relationships, such as whether increasing hurricane intensity aligns with decreasing ice extent, and whether climate change awareness has any connection with international happiness levels.

Our analyses involve data summarization, correlation testing, and visualization. By the end of this report, we will present findings that show connections of these climate-related issues.
Climate change is something that has been studied. Here's some relevant information about the context of our study.


# Data Description

## <<Data Set 1>>
```{r load_data1}
cyclones_data <- read_parquet("cyclones_data.parquet")
```
The data comes from Atlantic and North Pacific basins and describes detailed information on hurricanes.
The cyclone data includes key information that is essential for the analysis, grouped into the following categories:

Identification: Information to identify the cyclone's basin: Basin (geographical basin), Number (cyclone ID), Nameyear (year).
Time: Date and time of the cyclone's observation: ObservYear, Month, Day, Hour, Minute (date and time of observation).
Status and Location: The cyclone's current status and its geographical coordinates: Status (current status), Latitude, Longitude (coordinates).
Intensity: The cyclone's maximum wind speed and minimum central pressure, indicating its strength: Max_wind (maximum wind speed), Min_pressure (minimum pressure).

In order to clean the data, we began with the raw cyclone data, which was initially in an untidy format with multiple values stored in a single column. We used the separate_wider_delim() function to split the data into meaningful columns, creating new ones for attributes such as cyclone status, latitude, longitude, wind speed, pressure, and extent measurements. Missing values, represented by placeholders like "-999" and "-99", were replaced with NA. Latitude and longitude, originally stored as directional strings (e.g., "28.0N" or "94W"), were converted into numeric values using a custom function, convert_latlon(), which applies the correct sign based on the direction. The cyclones were then categorized by their maximum wind speed using the Saffir-Simpson Hurricane Wind Scale. Finally, the cleaned data from the Atlantic and North Pacific basins were combined into a single dataset using bind_rows().

## <<Data Set 2>>

```{r load_data2}
ice_extent_yearly <- read_parquet("ice_extent_yearly.parquet")
```
The data comes from the Arctic and the Antarctic poles and detail the yearly sea ice extent.
The Sea Ice data includes key information that is essential for the analysis, grouped into the following categories:

Temporal and Geographical Information:
Year: The year of the sea ice extent measurement.
Region: The geographical region (Arctic or Antarctic).

Sea Ice Extent:
Name: Indicates whether the value is the minimum or maximum sea ice extent for that year.
Value: The corresponding sea ice extent for that year, region, and type (min or max).

In order to clean the data, we began by reading the raw sea ice extent data from an Excel file, which contains separate sheets for the Arctic and Antarctic. We selected the relevant columns (month, day, and years from 1978 to 2023) and reshaped the data into a long format, where each row represents a specific date-year combination with the corresponding sea ice extent. Missing month values were filled using the fill() function, and rows with missing sea ice extent values were removed. A new date column was created by combining the year, month, and day, and a region column was added to distinguish between the Arctic and Antarctic data. The dataset was then grouped by year and region to calculate the yearly minimum and maximum ice extent, which was reshaped into a long format with columns for the type (min/max) and corresponding value (ice extent).

## <<Data Set 3>>

```{r load_data2}
climate_awareness <- read_parquet("climate_awareness.parquet")
```

The climate awareness data contains the proportion of people from each country who answered "no", "a little", ... to a question asking about their awareness of the actual definitions of climate change.

The climate awareness data includes key information that is essential for the analysis:
 - "Countries in pop_data that aren't in climate_awareness"
 - "Countries in aware_countries that aren't in pop_data"

In order to clean the data, we began by reading the climate awareness survey results from an Excel file. The relevant sheet was loaded and reshaped using pivot_longer() to convert the data from a wide to a long format, placing country names in a 'country' column and survey scores in a 'score' column. The values in the 'climate_awareness' column were then recoded into meaningful categories (e.g., 'aware_no', 'aware_alittle', etc.) using case_when(). This recoded column was renamed to 'answer'. Next, the data was pivoted back to a wider format using pivot_wider(), creating separate columns for each awareness level, with corresponding scores for each country. Finally, the cleaned data was saved in Parquet format for efficient storage and future use.

## Combining the Data

Explain how any combinations of data were performed. Explain what kind of join was needed, whether columns had to be modified (for example, matching "country" names.)





# Exploratory Data Analysis

To achieve our goals, we explored the data by...

We explored many aspects of the data, but will demonstrate three. These are <<insight 1>>, <<insight 2>>, and <<insight3>>

The first aspect that we found interesting is shown in \@ref(fig:insight1). The insight should be specific to the data shown, not a general statement beyond the data (leave that for the conclusion).

```{r insight1, fig.cap="This is a figure caption that you will need to change in order to get good marks in the visualization rubric items."}
# This is an example of how you can control figures and captions in
# an R chunk. Note that you can reference figures using:
# \@ref(fig:insight1), where "insight1" is the label of this code
# chunk (the first bit of text after the "r" in "```{r label, options...}")
```

This insight is supported by the summary statistics in table \@ref(tab:summary_stats)

```{r summary_stats}
# Calculate the relevant summary statistics here.
# Note that the "kable" function in the "knitr" package
# is convenient for making nice tables. Other packages can
# do much fancier things with tables, but keep in mind that
# the insights should be the star, not the formatting.
```

The next insight that we found is shown in \@ref(fig:insight2).

```{r insight2, fig.height=4, fig.width=6, fig.cap="This is a figure caption that you will need to change in order to get good marks in the visualization rubric items."}
# This figure will have a height of 4 and a width of 6.
# Feel free to change this, and to apply different sizes
# to the other figures you create.
```

Finally, \@ref(fig:insight3) shows ...

```{r insight3, fig.height=4, fig.width=6, fig.cap="This is a figure caption that you will need to change in order to get good marks in the visualization rubric items."}
```

# Conclusion and Future Work

Overall, we found <<general ideas>>.

A second paragraph about our findings.

The next steps in this analysis are...

The limitations of this analysis are as follows. (Do not simply list potential issues with sampling, but relate them to your analysis and how they affect your conclusions. An honest and complete acknowledgement of the limitations makes the analysis more trustworthy.)

# References

I am not strict about MLA or APA style or anything like that. For this report, I would much rather have your citations be easy to match to your insights.

The easiest way is to use Rmd's [footnote](https://bookdown.org/yihui/rmarkdown/markdown-syntax.html#inline-formatting) syntax. This will put a number beside the word where the footnote appears, and the full text of the footnote at the bottom of the page (pdf) or end of the document (html). The syntax is:^[See the source view to see this footnote], where I suggest that you put in something like this^[The relevance to the insight is ... . From <<name of source and name of article>>, published on <<date>>, url: <<link to page>>] to make references for this assignment.

Alternatively, you could make a list of citations with their main arguments and why they're relevent to your insights, methods, etc.

The link above also references "bibtex" files. These are also extremely convenient, but have a steep learning curve and they make it difficult to tie them to an insight. If you use bibtext, then make sure that you provide a sentence to describe the source and it's relevance when you cite it - don't just add citations to the end of a sentence (this is common practice in academia, but I want to know that your citations are directly relevant for this assignmnet).
